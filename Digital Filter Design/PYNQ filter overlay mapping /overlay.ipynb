## LOAD THE OVERLAY
import numpy as np
from pynq import allocate
from pynq import Overlay

ol = Overlay("/home/xilinx/jupyter_notebooks/lab3/base_filter.bit")

## PLAY THE AUDIO FILE
dma = ol.axi_dma

input_buffer = allocate(shape=(64,), dtype=np.uint32)
output_buffer = allocate(shape=(64,), dtype=np.uint32)

for i in range(64):
   input_buffer[i] = i+10

dma.sendchannel.transfer(input_buffer)
dma.sendchannel.wait()

print("Arrays are equal: {}".format(np.array_equal(input_buffer, output_buffer)))

pynqAudio = ol.audio_codec_ctrl_0 #might use the default app, so audio items might not work here. 

pynqAudio.set_volume(62)

pynqAudio.load("/home/xilinx/jupyter_notebooks/base/audio/audio.wav")
#make a local copy of the buffer to process and manipulate
pynqAudio_buffer = pynqAudio.buffer.copy()

pynqAudio.configure()
pynqAudio.play()
samplelen = len(pynqAudio.buffer)
print(samplelen)

## PROCESS THE AUDIO
%matplotlib inline
import wave
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from scipy.fftpack import fft

wav_path = "/home/xilinx/jupyter_notebooks/base/audio/audio.wav"
with wave.open(wav_path, 'r') as wav_file:
    raw_frames = wav_file.readframes(-1)
    num_frames = wav_file.getnframes()
    num_channels = wav_file.getnchannels()
    sample_rate = wav_file.getframerate()
    sample_width = wav_file.getsampwidth()

inbuffer = allocate(shape=(samplelen,), dtype=np.int32)
outbuffer = allocate(shape=(samplelen,), dtype=np.int32)


temp_buffer = np.empty((num_frames, num_channels, 4), dtype=np.uint8)
bytes_raw = np.frombuffer(pynqAudio_buffer, dtype=np.uint8)

#Decode raw interleaved channel data into each channel with 4 bytes per channel- note that the upper bytes would be '0' and not properly sign extended
temp_buffer[:, :, :] = bytes_raw.reshape(-1, num_channels, 4) 
temp_buffer[:, :, sample_width:] = (temp_buffer[:, :, sample_width-1:sample_width] >> 7) * 255 #Sign extend the buffer
frames = temp_buffer.view('<i4').reshape(temp_buffer.shape[:-1]) #Compose it back to int32 format (signed), little endian format
inbuffee = np.concatenate(frames.transpose(),0) #Concatenate the two channels without interleaving
inbuffer[:] = inbuffee[:]

for i in range(10):
    print(pynqAudio_buffer[i], inbuffer[i], frames[i], temp_buffer[i])


## IMPLEMENT FIR FILTER
import time
st = time.time()
dma.sendchannel.transfer(inbuffer)
dma.recvchannel.transfer(outbuffer)
dma.sendchannel.wait()
dma.recvchannel.wait()
et = time.time()

hw_exec_time = et - st
print("Hardware Execution time is: ",hw_exec_time)
len(outbuffer)

outbuff_ser = np.split(outbuffer,2)
outbuff_trans = np.transpose(outbuff_ser)
outbuff_fin = np.concatenate(outbuff_trans)

pynqAudio.buffer = outbuff_fin.copy()
pynqAudio.play()

## PLOT THE AUDIO
temp_buffer = np.empty((num_frames, num_channels, 4), dtype=np.uint8)
raw_bytes = np.frombuffer(raw_frames, dtype=np.uint8)
temp_buffer[:, :, :sample_width] = raw_bytes.reshape(-1, num_channels, 
                                                    sample_width)
temp_buffer[:, :, sample_width:] = \
    (temp_buffer[:, :, sample_width-1:sample_width] >> 7) * 255

frames = temp_buffer.view('<i4').reshape(temp_buffer.shape[:-1])
print(np.shape(temp_buffer))

for channel_index in range(num_channels):
    plt.figure(num=None, figsize=(15, 3))
    plt.title('Audio in Time Domain (Channel {})'.format(channel_index))
    plt.xlabel('Time in s')
    plt.ylabel('Amplitude')
    time_axis = np.arange(0, num_frames/sample_rate, 1/sample_rate)
    plt.plot(time_axis, frames[:, channel_index])
    plt.show()

## COMPARE FILTERED TO OG SIGNAL
temp_out = np.empty((num_frames, num_channels, 4), dtype=np.uint8)
raw_out = np.frombuffer(outbuff_fin, dtype=np.uint8)
temp_out[:, :, :] = raw_out.reshape(-1, num_channels, 4)
frames_out = temp_out.view('<i4').reshape(temp_out.shape[:-1])

for channel_index in range(num_channels):
    plt.figure(num=None, figsize=(15, 3))
    plt.title('Audio in Time Domain (Channel {})'.format(channel_index))
    plt.xlabel('Time in s')
    plt.ylabel('Amplitude')
    time_axis = np.arange(0, num_frames/sample_rate, 1/sample_rate)
    plt.plot(time_axis, frames_out[:, channel_index], 'y-', label="HW Filter")
    #plt.plot(time_axis, frames[:,channel_index], 'g-', label="Audio Input")
    plt.legend()
    plt.show()


## COMPARE TO SOFTWARE EXECUTION FILTER
from scipy.signal import lfilter
coeffs = [-2304,
-67,
-83,
-738,
-1368,
-1025,
-1311,
-1293,
-1296,
-1296,
-1280,
-1377,
-1413,
-1530,
-1546,
-1696,
-824,
-818,
-1119,
-232,
-170,
-221,
-84,
-549,
-908,
-1136,
-1021,
-1004,
-1557,
-1000,
-824,
-767,
-775,
-793,
-835,
-1584,
-1313,
-992,
-916,
-1084,
129,
476,
634,
569,
261,
-337,
-818,
-1983,
-1000,
-1247,
-1503,
-1792,
-1801,
-1871,
-1892,
-1817,
-1911,
-835,
-1173,
-924,
2275,
5146,
8126,
11113,
13886,
16462,
18587,
20250,
21244,
21549,
21244,
20250,
18587,
16462,
13886,
11113,
8126,
5146,
2275,
-924,
-1173,
-835,
-1911,
-1817,
-1892,
-1871,
-1801,
-1792,
-1503,
-1247,
-1000,
-1983,
-818,
-337,
261,
569,
634,
476,
129,
-1084,
-916,
-992,
-1313,
-1584,
-835,
-793,
-775,
-767,
-824,
-1000,
-1557,
-1004,
-1021,
-1136,
-908,
-549,
-84,
-221,
-170,
-232,
-1119,
-818,
-824,
-1696,
-1546,
-1530,
-1413,
-1377,
-1280,
-1296,
-1296,
-1293,
-1311,
-1025,
-1368,
-738,
-83,
-67,
-2304]
print(len(coeffs))

## CALCULATE SOFTWARE EX. TIME
st = time.time()
swfilter = lfilter(coeffs, 128e3, inbuffer)
et = time.time()
sw_exec_time = et - st
print ("Software execution time: ", sw_exec_time)

# View the output as int32 type instead of float64 inferred by lfilter
swfilter = swfilter.astype(np.int32)

# Now let us convert the serialised format back to the two channel format
swbuff_ser = np.split(swfilter,2)
swbuff_trans = np.transpose(swbuff_ser)
swbuff_fin = np.concatenate(swbuff_trans)

temp_out_sw = np.empty((num_frames, 2, 4), dtype=np.uint8)
raw_out_sw = np.frombuffer(swbuff_fin, dtype=np.uint8)
temp_out_sw[:, :, :] = raw_out_sw.reshape(-1, 2, 4)
frames_out = temp_out.view('<i4').reshape(temp_out.shape[:-1])

## PLOT SOFTWARE IMPLEMENTATION
plt.figure(num=None, figsize=(15, 3))
plt.title('Audio in Time Domain (Channel {})'.format(0))
plt.xlabel('Time in s')
plt.ylabel('Amplitude')
time_axis = np.arange(0, num_frames/sample_rate, 1/sample_rate)
plt.plot(time_axis, frames_out[:,0], 'y-', label="SW Filter")
#plt.plot(time_axis, frames[:,0], 'g-', label = "Input Audio")
plt.show()
